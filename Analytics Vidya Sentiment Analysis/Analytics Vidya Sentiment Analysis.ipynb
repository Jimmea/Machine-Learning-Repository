{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import nltk\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the option  to display the entire text row\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is so selfish he drags his kids into his dysfunction.   #run</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't use cause they don't offer wheelchair vans in pdx.    #disapointed #getthanked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in urð±!!! ðððð",
       "ð¦ð¦ð¦</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label  \\\n",
       "0  1   0       \n",
       "1  2   0       \n",
       "2  3   0       \n",
       "3  4   0       \n",
       "4  5   0       \n",
       "\n",
       "                                                                                                                        tweet  \n",
       "0   @user when a father is dysfunctional and is so selfish he drags his kids into his dysfunction.   #run                      \n",
       "1  @user @user thanks for #lyft credit i can't use cause they don't offer wheelchair vans in pdx.    #disapointed #getthanked  \n",
       "2    bihday your majesty                                                                                                       \n",
       "3  #model   i love u take with u all the time in urð±!!! ðððð\n",
       "ð¦ð¦ð¦                                        \n",
       "4   factsguide: society now    #motivation                                                                                     "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the data set\n",
    "dr=\"C:\\\\NLP in Python\\\\Sentiment Analysis Analytics Vidya\"\n",
    "df_train=pd.read_csv(dr+\"\\\\train_E6oV3lV.csv\")\n",
    "df_train.head()\n",
    "\n",
    "# There are three columns\n",
    "# 1: id\n",
    "# 2: label (1 and 0)\n",
    "# 3: tweet (text form)\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31962, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape\n",
    "# 31962 rows and three columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the frequency distribution\n",
    "df_train['label'].value_counts()\n",
    "# 29720 '0'\n",
    "# 2242 '1'\n",
    "zeroes_cnt=df_train['label'].value_counts()[0]\n",
    "ones_cnt=df_train['label'].value_counts()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the data set\n",
    "# creating the stop word list\n",
    "# Removing rows corresponding to stop word\n",
    "# Stop word removal using inbuilt and custom list\n",
    "from nltk.corpus import stopwords\n",
    "stop = set(stopwords.words('english'))\n",
    "stop2=list(stop)\n",
    "stop2.extend(['@user','@user @user','&amp;','@user @user @user','-','u','Ã¢Â€Â“',\n",
    "             'Ã¢Â€Â”','Ã¢Â€Â¦','Ã¢Â†Â','Ã¢ÂÂ¤','Ã¢ÂÂ¤Ã¯Â¸Â','Ã°ÂŸÂ’Â•','Ã°ÂŸÂ’Â¦Ã°ÂŸÂ’Â¦Ã°ÂŸÂ’Â¦',\n",
    "             'Ã°ÂŸÂ”Â','Ã°ÂŸÂ”Â  #love','Ã°ÂŸÂ”Â  #love  #instagood',\n",
    "             'Ã°ÂŸÂ˜','Ã°ÂŸÂ˜Â€','Ã°ÂŸÂ˜Â','Ã°ÂŸÂ˜Â‚','Ã°ÂŸÂ˜Â„',\n",
    "            'Ã°ÂŸÂ˜ÂŠ','Ã°ÂŸÂ˜Â','Ã°ÂŸÂ˜Â”','Ã°ÂŸÂ˜Â˜','Ã°ÂŸÂ˜Â™Ã°ÂŸÂ˜ÂŽÃ°ÂŸÂ‘Â„Ã°ÂŸÂ‘',\n",
    "            'Ã°ÂŸÂ˜Â™Ã°ÂŸÂ˜ÂŽÃ°ÂŸÂ‘Â„Ã°ÂŸÂ‘  Ã°ÂŸÂ’Â¦Ã°ÂŸÂ’Â¦Ã°ÂŸÂ’Â¦','Ã°ÂŸÂ˜Â¢',\n",
    "             'Ã¢Â€Â¦','!!','!!!','Ã¢Â€Â¦',        'Ã¢Â€Â¦','2','Ã°ÂŸÂ’Â¦Ã°ÂŸÂ’Â¦Ã°ÂŸÂ’Â¦',\n",
    "            'Ã°ÂŸÂ˜Â™Ã°ÂŸÂ˜ÂŽÃ°ÂŸÂ‘Â„Ã°ÂŸÂ‘  Ã°ÂŸÂ’Â¦Ã°ÂŸÂ’Â¦Ã°ÂŸÂ’Â¦','Ã°ÂŸÂ˜Â™Ã°ÂŸÂ˜ÂŽÃ°ÂŸÂ‘Â„Ã°ÂŸÂ‘',\n",
    "            '...','Ã¢Â†Â','4','1','3','Ã°ÂŸÂ˜ÂŠ','Ã¢ÂÂ¤Ã¯Â¸Â','.@user','#a','5',':(','Ã°ÂŸÂ˜Â','Ã¢Â€Â“',\n",
    "            '..','Ã°ÂŸÂ˜Â‚','Ã°ÂŸÂ˜Â”','10','Ã°ÂŸÂ˜Â','1st','7','Ã°ÂŸÂ˜Â¢','#Ã¢Â€Â¦','6','Ã°ÂŸÂ˜Â€','Ã°ÂŸÂ˜Â˜',\n",
    "              'Ã°ÂŸÂ’Â•','Ã°ÂŸÂ”Â','Ã¢ÂÂ¤','Ã°ÂŸÂ˜Â„','Ã°ÂŸÂ”Â  #love','50','2nd','8','Ã¢Â€Â”','Ã°ÂŸÂ˜','3d:',\n",
    "                'ð\\x9f\\x98\\x99ð\\x9f\\x98\\x8eð\\x9f\\x91\\x84ð\\x9f\\x91  ð\\x9f\\x92¦ð\\x9f\\x92¦ð\\x9f\\x92¦',\n",
    "              'Ã°ÂŸÂ˜Â™Ã°ÂŸÂ˜ÂŽÃ°ÂŸÂ‘Â„Ã°ÂŸÂ‘Â…Ã°ÂŸÂ’Â¦Ã°ÂŸÂ’Â¦Ã°ÂŸÂ’Â¦'\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to analyse the text data stored in the 'tweet' column\n",
    "# Before that lets define some key functions\n",
    "# Creating functions to do tokenisation and punctuation removal\n",
    "\n",
    "# White space tokenizer\n",
    "def tokenize(text):\n",
    "    tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "    token = []\n",
    "    for item in text:\n",
    "        token.append(tokenizer.tokenize(item))\n",
    "        \n",
    "    # Removing stop words\n",
    "    ls_dummy1=[]\n",
    "    ls_dummy2=[]\n",
    "    temp=1\n",
    "    for i in token:\n",
    "        ls_dummy1=[]\n",
    "        for j in i:\n",
    "            if j in stop2:\n",
    "                temp=1\n",
    "            else:\n",
    "                ls_dummy1.append(j)\n",
    "        ls_dummy2.append(ls_dummy1)\n",
    "    l3=ls_dummy2\n",
    "        \n",
    "    return l3\n",
    "\n",
    "# Creating a function for removing the puntuation from text\n",
    "def rem_punctuation(data_frame,colname):\n",
    "    l3=[]\n",
    "    l2=[i for i in data_frame[colname]]\n",
    "    l3=tokenize(l2)\n",
    "\n",
    "    # Removing the punctuations\n",
    "    l5=[]\n",
    "    l6=[]\n",
    "    for j in l3:\n",
    "        for k in j:\n",
    "            if k in string.punctuation:\n",
    "                temp=1\n",
    "            else:\n",
    "                l5.append(k)\n",
    "        l6.append(l5)\n",
    "        l5=[]\n",
    "    c_ls=[\" \".join(i) for i in l6]\n",
    "    df1=pd.DataFrame(c_ls)\n",
    "    df1.columns=['Text']\n",
    "    return(df1)\n",
    "\n",
    "# We will now create a function that takes in text and ngram list\n",
    "# text/document is stores in a list\n",
    "# list also specifies ngram paramter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk import word_tokenize\n",
    "\n",
    "# The function should take the column containing text data\n",
    "def TF_NGRAM(data_frame,colname,ngram):\n",
    "    # Tokenize the data\n",
    "    DocID_ls=[]\n",
    "\n",
    "    #Appending the Doc_ID column\n",
    "    data_frame['Doc_ID']=[i for i in range(1,data_frame[colname].shape[0]+1)]\n",
    "\n",
    "\n",
    "    from nltk import ngrams       \n",
    "    l1=[]\n",
    "    for i in data_frame['Doc_ID']:\n",
    "        for k in data_frame[data_frame['Doc_ID']==i][colname]:\n",
    "            for j in ngram:\n",
    "                unigrams = ngrams(k.split(), j)\n",
    "                for z in unigrams:\n",
    "                    if j==1:\n",
    "                        l1.append(z[0])\n",
    "                    elif j==2:\n",
    "                        l1.append(z[0] + \" , \" +z[1])\n",
    "                    elif j==3:\n",
    "                        l1.append(z[0] + \" , \" +z[1]+\" , \" +z[2])\n",
    "                    elif j==4:\n",
    "                        l1.append(z[0] + \" , \" +z[1]+\" , \" +z[2] +\" , \" +z[3])\n",
    "\n",
    "                    DocID_ls.append(i)\n",
    "\n",
    "    # Creating a Data Frame out of it\n",
    "\n",
    "    s1=pd.Series(l1)\n",
    "    s2=pd.Series(DocID_ls)\n",
    "    df1=pd.DataFrame(s2)\n",
    "    df1['s1']=s1\n",
    "    df1.columns=['Doc_ID','Tokens']\n",
    "    df1\n",
    "    return(df1)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is so selfish he drags his kids into his dysfunction.   #run</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't use cause they don't offer wheelchair vans in pdx.    #disapointed #getthanked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ur!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label  \\\n",
       "0  1   0       \n",
       "1  2   0       \n",
       "2  3   0       \n",
       "3  4   0       \n",
       "4  5   0       \n",
       "\n",
       "                                                                                                                        tweet  \n",
       "0   @user when a father is dysfunctional and is so selfish he drags his kids into his dysfunction.   #run                      \n",
       "1  @user @user thanks for #lyft credit i can't use cause they don't offer wheelchair vans in pdx.    #disapointed #getthanked  \n",
       "2    bihday your majesty                                                                                                       \n",
       "3  #model   i love u take with u all the time in ur!!!                                                                         \n",
       "4   factsguide: society now    #motivation                                                                                     "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If you look closely, there are certain characters such as Ã°ÂŸÂ’Â¦Ã°ÂŸÂ’Â¿Ã¢ÂœÂ (row 4 for instance)\n",
    "# These are meaningless and hence they need to be removed\n",
    "# Removing the special character/ascii character\n",
    "twt=[str(i).encode('ascii', 'ignore').decode(\"utf-8\") for i in df_train['tweet'] ]\n",
    "df_train['tweet']=twt\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31962, 3)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removing the special characters doesnt reduce the number of records \n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing punctuations, stop words etc\n",
    "df=rem_punctuation(df_train,'tweet')\n",
    "df.head()\n",
    "df.to_csv(dr + \"\\\\cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Doc_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>father dysfunctional selfish drags kids dysfunction. #run</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>thanks #lyft credit can't use cause offer wheelchair vans pdx. #disapointed #getthanked</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bihday majesty</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#model love take time ur!!!</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>factsguide: society #motivation</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                      Text  \\\n",
       "0  father dysfunctional selfish drags kids dysfunction. #run                                 \n",
       "1  thanks #lyft credit can't use cause offer wheelchair vans pdx. #disapointed #getthanked   \n",
       "2  bihday majesty                                                                            \n",
       "3  #model love take time ur!!!                                                               \n",
       "4  factsguide: society #motivation                                                           \n",
       "\n",
       "   Doc_ID  \n",
       "0  1       \n",
       "1  2       \n",
       "2  3       \n",
       "3  4       \n",
       "4  5       "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Doc_ID']=range(1,df.shape[0]+1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31962, 2)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape\n",
    "# So no rows were removed during punctuation and stop word removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19, 2)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating the total number of blanks in df\n",
    "#len(np.where(df['Text'].applymap(lambda x: x == ''))[0]) # 19 ff them\n",
    "blnk_Doc_ID=df['Text']==\"\"\n",
    "df[blnk_Doc_ID].shape\n",
    "\n",
    "# There are 19 Doc_ID which are blank after Removing punctuations, stop words etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1961     1962 \n",
       "3351     3352 \n",
       "3982     3983 \n",
       "4411     4412 \n",
       "4799     4800 \n",
       "5235     5236 \n",
       "5309     5310 \n",
       "7939     7940 \n",
       "9034     9035 \n",
       "10461    10462\n",
       "10802    10803\n",
       "13038    13039\n",
       "13287    13288\n",
       "13848    13849\n",
       "13862    13863\n",
       "16320    16321\n",
       "20261    20262\n",
       "25629    25630\n",
       "28513    28514\n",
       "Name: Doc_ID, dtype: int32"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Storing the Doc_ID's that have blank in 'Text'\n",
    "ls_blnk_Doc_ID=df[blnk_Doc_ID]['Doc_ID']\n",
    "ls_blnk_Doc_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Doc_ID</th>\n",
       "      <th>Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>father</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>dysfunctional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>selfish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>drags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>kids</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>dysfunction.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>#run</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>father , dysfunctional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>dysfunctional , selfish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>selfish , drags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>drags , kids</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Doc_ID                   Tokens\n",
       "0   1       father                 \n",
       "1   1       dysfunctional          \n",
       "2   1       selfish                \n",
       "3   1       drags                  \n",
       "4   1       kids                   \n",
       "5   1       dysfunction.           \n",
       "6   1       #run                   \n",
       "7   1       father , dysfunctional \n",
       "8   1       dysfunctional , selfish\n",
       "9   1       selfish , drags        \n",
       "10  1       drags , kids           "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ngram frequency analysis\n",
    "# checking the ngram distribution\n",
    "ngram_df=TF_NGRAM(df,'Text',[1,2,3])\n",
    "ngram_df.head(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31943"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the number of unique 'Doc_ID' in ngram_df\n",
    "len(ngram_df['Doc_ID'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Doc_ID</th>\n",
       "      <th>Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>father</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>dysfunctional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>selfish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>drags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>kids</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Doc_ID         Tokens\n",
       "0  1       father       \n",
       "1  1       dysfunctional\n",
       "2  1       selfish      \n",
       "3  1       drags        \n",
       "4  1       kids         "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace all , in Tokens with \"\"\n",
    "import re\n",
    "ngram_df['Tokens']=ngram_df['Tokens'].apply(lambda x: re.sub(',','',x))\n",
    "ngram_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Doc_ID', 'Tokens'], dtype='object')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(666358, 2)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31943"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the number of unique 'Doc_ID' in ngram_df\n",
    "len(ngram_df['Doc_ID'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we add the ones that had blanks in df (19 of them), then we would get 31962 which is the \n",
    "# total count of Doc_ID in the input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Doc_ID</th>\n",
       "      <th>Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>dummy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>dummy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>dummy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>dummy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>dummy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Doc_ID Tokens\n",
       "0  1       dummy\n",
       "1  2       dummy\n",
       "2  3       dummy\n",
       "3  4       dummy\n",
       "4  5       dummy"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a Data Frame that has 'dummy' values for all Doc_ID\n",
    "#ls_blnk_Doc_ID=list(blnk_Doc_ID)\n",
    "\n",
    "blnk_df=pd.DataFrame(df['Doc_ID'],columns=['Doc_ID'])\n",
    "blnk_df['Tokens']='dummy'\n",
    "blnk_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(666358, 2)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31962"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Binding ngram_df and blnk_df row wise\n",
    "ngram_df2=pd.concat([ngram_df,blnk_df],axis=0)\n",
    "len(ngram_df2['Doc_ID'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Doc_ID</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>#run</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>drags</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>drags  kids</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>drags  kids  dysfunction.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>dummy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Doc_ID                     Tokens  Frequency\n",
       "0  1       #run                       1        \n",
       "1  1       drags                      1        \n",
       "2  1       drags  kids                1        \n",
       "3  1       drags  kids  dysfunction.  1        \n",
       "4  1       dummy                      1        "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a summary at Doc_ID and Tokens level\n",
    "ngram_df2['Frequency']=1\n",
    "ngram_df0=ngram_df2.groupby(['Doc_ID','Tokens'])['Frequency'].sum().reset_index()\n",
    "ngram_df0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dummy</td>\n",
       "      <td>31962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#love</td>\n",
       "      <td>1509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>day</td>\n",
       "      <td>1482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>happy</td>\n",
       "      <td>1314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>love</td>\n",
       "      <td>1104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  Count\n",
       "0  dummy  31962\n",
       "1  #love  1509 \n",
       "2  day    1482 \n",
       "3  happy  1314 \n",
       "4  love   1104 "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the summary at an overall level\n",
    "freq_dist=nltk.FreqDist(ngram_df0['Tokens'])\n",
    "df5=pd.DataFrame(pd.Series(freq_dist),columns=['Count'])\n",
    "df5.sort_values(['Count'])\n",
    "df6=df5.sort_values(['Count'],ascending=False).reset_index()\n",
    "df6.shape # 827k records\n",
    "df6.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(871, 2)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filtering out the ngrams\n",
    "df7=df6[df6['Count'] > 50]\n",
    "df7.shape\n",
    "# For the first run lets keep features identified in df7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing the tokens to a file\n",
    "df7.to_csv(dr+\"\\\\tokens.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "871"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token=[i for i in df7['index']]\n",
    "len(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Doc_ID</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>dummy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>father</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>kids</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2</td>\n",
       "      <td>can't</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2</td>\n",
       "      <td>cause</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Doc_ID  Tokens  Frequency\n",
       "4   1       dummy   1        \n",
       "10  1       father  1        \n",
       "13  1       kids    1        \n",
       "25  2       can't   1        \n",
       "28  2       cause   1        "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the DTM\n",
    "\n",
    "pos=[i in token for i in ngram_df0['Tokens']] # filtering on the tokens given in 'token' list\n",
    "ngram_df_DTM0=ngram_df0[pos]\n",
    "ngram_df_DTM0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150469, 3)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram_df_DTM0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Tokens</th>\n",
       "      <th>Doc_ID</th>\n",
       "      <th>#2016</th>\n",
       "      <th>#affirmation</th>\n",
       "      <th>#affirmations</th>\n",
       "      <th>#allahsoil</th>\n",
       "      <th>#altwaystoheal</th>\n",
       "      <th>#altwaystoheal  #healthy</th>\n",
       "      <th>#amazing</th>\n",
       "      <th>#anxiety</th>\n",
       "      <th>#awesome</th>\n",
       "      <th>...</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>yes</th>\n",
       "      <th>yet</th>\n",
       "      <th>yo</th>\n",
       "      <th>you</th>\n",
       "      <th>you!</th>\n",
       "      <th>you.</th>\n",
       "      <th>you?</th>\n",
       "      <th>young</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 872 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Tokens  Doc_ID  #2016  #affirmation  #affirmations  #allahsoil  \\\n",
       "0       1       0.0    0.0           0.0            0.0          \n",
       "1       2       0.0    0.0           0.0            0.0          \n",
       "2       3       0.0    0.0           0.0            0.0          \n",
       "3       4       0.0    0.0           0.0            0.0          \n",
       "4       5       0.0    0.0           0.0            0.0          \n",
       "\n",
       "Tokens  #altwaystoheal  #altwaystoheal  #healthy  #amazing  #anxiety  \\\n",
       "0       0.0             0.0                       0.0       0.0        \n",
       "1       0.0             0.0                       0.0       0.0        \n",
       "2       0.0             0.0                       0.0       0.0        \n",
       "3       0.0             0.0                       0.0       0.0        \n",
       "4       0.0             0.0                       0.0       0.0        \n",
       "\n",
       "Tokens  #awesome  ...    year  years  yes  yet   yo  you  you!  you.  you?  \\\n",
       "0       0.0       ...    0.0   0.0    0.0  0.0  0.0  0.0  0.0   0.0   0.0    \n",
       "1       0.0       ...    0.0   0.0    0.0  0.0  0.0  0.0  0.0   0.0   0.0    \n",
       "2       0.0       ...    0.0   0.0    0.0  0.0  0.0  0.0  0.0   0.0   0.0    \n",
       "3       0.0       ...    0.0   0.0    0.0  0.0  0.0  0.0  0.0   0.0   0.0    \n",
       "4       0.0       ...    0.0   0.0    0.0  0.0  0.0  0.0  0.0   0.0   0.0    \n",
       "\n",
       "Tokens  young  \n",
       "0       0.0    \n",
       "1       0.0    \n",
       "2       0.0    \n",
       "3       0.0    \n",
       "4       0.0    \n",
       "\n",
       "[5 rows x 872 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pivotting df3 \n",
    "ngram_df_DTM=ngram_df_DTM0.pivot(index='Doc_ID',columns='Tokens',values='Frequency').fillna(0).reset_index()\n",
    "ngram_df_DTM.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31962, 872)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram_df_DTM.shape\n",
    "# ngram_df_DTM has all the Doc_IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing the columns to a csv\n",
    "clm=ngram_df_DTM.columns\n",
    "np.array([clm])\n",
    "#pd.DataFrame(np.array([clm]).to_csv(\"C:\\\\NLP in Python\\\\Sentiment Analysis Analytics Vidya\\\\final_features.csv\")\n",
    "ngram_df_DTM.to_csv(\"C:\\\\NLP in Python\\\\Sentiment Analysis Analytics Vidya\\\\ngram_DTM.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31962, 872)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dimension of ngram_df_DTM\n",
    "ngram_df_DTM.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31962, 875)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Joining this with the 'id' column from input data frame(df_train) to bring in the labels \n",
    "\n",
    "# LEFT JOIN\n",
    "df_final=pd.merge(ngram_df_DTM,df_train,left_on='Doc_ID',right_on='id',how='left')\n",
    "df_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Doc_ID</th>\n",
       "      <th>#2016</th>\n",
       "      <th>#affirmation</th>\n",
       "      <th>#affirmations</th>\n",
       "      <th>#allahsoil</th>\n",
       "      <th>#altwaystoheal</th>\n",
       "      <th>#altwaystoheal  #healthy</th>\n",
       "      <th>#amazing</th>\n",
       "      <th>#anxiety</th>\n",
       "      <th>#awesome</th>\n",
       "      <th>...</th>\n",
       "      <th>yet</th>\n",
       "      <th>yo</th>\n",
       "      <th>you</th>\n",
       "      <th>you!</th>\n",
       "      <th>you.</th>\n",
       "      <th>you?</th>\n",
       "      <th>young</th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is so selfish he drags his kids into his dysfunction.   #run</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't use cause they don't offer wheelchair vans in pdx.    #disapointed #getthanked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ur!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 875 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Doc_ID  #2016  #affirmation  #affirmations  #allahsoil  #altwaystoheal  \\\n",
       "0  1       0.0    0.0           0.0            0.0         0.0              \n",
       "1  2       0.0    0.0           0.0            0.0         0.0              \n",
       "2  3       0.0    0.0           0.0            0.0         0.0              \n",
       "3  4       0.0    0.0           0.0            0.0         0.0              \n",
       "4  5       0.0    0.0           0.0            0.0         0.0              \n",
       "\n",
       "   #altwaystoheal  #healthy  #amazing  #anxiety  #awesome  \\\n",
       "0  0.0                       0.0       0.0       0.0        \n",
       "1  0.0                       0.0       0.0       0.0        \n",
       "2  0.0                       0.0       0.0       0.0        \n",
       "3  0.0                       0.0       0.0       0.0        \n",
       "4  0.0                       0.0       0.0       0.0        \n",
       "\n",
       "                                                              ...                                                              \\\n",
       "0                                                             ...                                                               \n",
       "1                                                             ...                                                               \n",
       "2                                                             ...                                                               \n",
       "3                                                             ...                                                               \n",
       "4                                                             ...                                                               \n",
       "\n",
       "   yet   yo  you  you!  you.  you?  young  id  label  \\\n",
       "0  0.0  0.0  0.0  0.0   0.0   0.0   0.0    1   0       \n",
       "1  0.0  0.0  0.0  0.0   0.0   0.0   0.0    2   0       \n",
       "2  0.0  0.0  0.0  0.0   0.0   0.0   0.0    3   0       \n",
       "3  0.0  0.0  0.0  0.0   0.0   0.0   0.0    4   0       \n",
       "4  0.0  0.0  0.0  0.0   0.0   0.0   0.0    5   0       \n",
       "\n",
       "                                                                                                                      tweet_y  \n",
       "0   @user when a father is dysfunctional and is so selfish he drags his kids into his dysfunction.   #run                      \n",
       "1  @user @user thanks for #lyft credit i can't use cause they don't offer wheelchair vans in pdx.    #disapointed #getthanked  \n",
       "2    bihday your majesty                                                                                                       \n",
       "3  #model   i love u take with u all the time in ur!!!                                                                         \n",
       "4   factsguide: society now    #motivation                                                                                     \n",
       "\n",
       "[5 rows x 875 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "nm=pd.DataFrame(df_final.columns,columns=['Col_Name'])\n",
    "nm.to_csv(\"C:\\\\NLP in Python\\\\Sentiment Analysis Analytics Vidya\\\\Final_Features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    29720\n",
       "1    2242 \n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking the number of ones in label column\n",
    "df_final['label'].value_counts()\n",
    "\n",
    "# in the input train data, following is the 0 and 1 distribution\n",
    "# 29720 '0'\n",
    "# 2242 '1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***We have made the Doc_Feature Matrix  \n",
    "Now we need to train the model with the labels***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries for building the model\n",
    "# mostly it will be the functions around sklearn library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "plt.rc(\"font\", size=14)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# Feature Selection\n",
    "from sklearn import datasets\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(style=\"white\")\n",
    "sns.set(style=\"whitegrid\", color_codes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "870"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Independent variable list\n",
    "df_final.columns\n",
    "\n",
    "# Removing 'dummy' column from the list\n",
    "df_final2=df_final.drop(['Doc_ID','dummy','id','label','tweet_y'],axis=1)\n",
    "\n",
    "# Storing the IV list in X\n",
    "X=list(df_final2.columns)\n",
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets run the Model\n",
    "# Splitting the data into test and train\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train=df_final[X]\n",
    "y_train = df_final['label']\n",
    "\n",
    "\n",
    "# Importing Logistic regression model from sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Making an instance of the model\n",
    "LogisticRegr = LogisticRegression()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pverma026\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 5.60783127e-01, -7.29882363e-01, -4.58225888e-01,\n",
       "         5.10640397e+00, -8.28908511e-01, -5.50134729e-01,\n",
       "        -9.82675951e-01, -5.77744631e-01, -8.80486462e-01,\n",
       "        -7.47357709e-01, -7.29184162e-01, -1.28962579e+00,\n",
       "        -4.88446507e-03, -4.40870801e-01, -1.77078266e+00,\n",
       "         1.34571555e+00, -1.55669141e+00, -9.64925617e-01,\n",
       "        -5.24847287e-01, -3.63704504e-01, -8.27034328e-01,\n",
       "        -9.18130568e-01, -1.31841047e+00, -5.16305244e-01,\n",
       "        -7.32235868e-01, -7.66550394e-02, -7.66550394e-02,\n",
       "        -1.49638026e+00, -4.12207538e-03, -4.08818852e-03,\n",
       "        -3.88165048e-01, -8.74889815e-01, -1.44728862e+00,\n",
       "        -1.05186254e-01, -1.07328893e+00, -9.44441896e-01,\n",
       "        -7.20593218e-02, -7.20593218e-02, -7.20593218e-02,\n",
       "        -1.10869645e+00,  9.69564601e-01, -9.24464168e-01,\n",
       "        -1.68905531e+00, -1.51987250e+00, -9.91610373e-01,\n",
       "        -5.58797201e-01, -6.45245937e-01, -6.22710348e-01,\n",
       "        -1.56141247e+00, -1.03256705e+00, -1.09474195e+00,\n",
       "        -9.08027273e-01, -1.84977242e-01, -2.33170077e-02,\n",
       "        -4.57260383e-01, -3.34325067e-01, -7.23384590e-01,\n",
       "        -1.60264944e+00, -6.56620540e-01, -1.37115437e-01,\n",
       "        -1.46948969e+00, -1.66571981e+00, -1.06308320e+00,\n",
       "        -3.98924048e-01, -1.24448451e+00, -7.79845673e-01,\n",
       "        -7.06949394e-01, -3.09572043e-01, -6.23556569e-01,\n",
       "        -8.70033199e-01, -1.30877762e+00, -3.15927418e-01,\n",
       "        -5.11594936e-01, -6.88934319e-01, -1.61329792e+00,\n",
       "        -8.94804819e-01,  2.34042141e+00, -5.82811579e-01,\n",
       "        -9.08231659e-01, -2.09955442e+00, -8.54392696e-01,\n",
       "        -3.93441218e-01, -7.66550394e-02, -3.84268922e-01,\n",
       "        -9.00337045e-01, -4.13118065e-01, -4.13118065e-01,\n",
       "        -4.13118065e-01, -1.11286839e+00, -1.07548419e+00,\n",
       "        -1.74067766e-02, -3.28424709e-03, -7.86458285e-01,\n",
       "        -7.76453474e-01, -2.03806546e-01,  5.35303460e-01,\n",
       "         8.46462028e-01,  1.40335902e-01,  2.02235824e+00,\n",
       "         1.40335902e-01,  1.40335902e-01, -1.54234902e+00,\n",
       "        -4.94526414e-01, -1.84901468e-01, -7.20593218e-02,\n",
       "        -8.53412265e-01, -3.68390546e-01, -3.43716669e-01,\n",
       "        -8.60759125e-01, -1.47171803e+00, -1.50010052e-02,\n",
       "        -1.11670497e-02, -5.32935556e-01, -2.35070086e-02,\n",
       "        -4.50052924e-03,  1.18107321e+00, -3.59475354e-01,\n",
       "        -5.34574142e-01, -2.97863879e-01, -2.97863879e-01,\n",
       "        -8.56505790e-01, -6.54793079e-01, -1.67336120e+00,\n",
       "        -1.33228307e+00, -9.97654663e-01, -2.60748298e-01,\n",
       "        -1.01472026e+00,  7.62035896e-01, -5.58061588e-01,\n",
       "        -2.23443902e+00, -1.04559651e+00, -7.35145779e-01,\n",
       "         1.10588745e+00, -3.19912976e-02, -7.84703889e-01,\n",
       "        -1.08831433e+00, -4.96935055e-01, -3.28424709e-03,\n",
       "        -3.28424709e-03, -5.68574683e-01,  2.30977795e+00,\n",
       "        -3.80566929e-01, -1.88410436e+00, -6.40371277e-01,\n",
       "        -1.52149877e+00, -1.34777970e+00, -1.11878508e+00,\n",
       "        -9.14478102e-01, -8.17840970e-01,  1.20544145e+00,\n",
       "        -8.26069152e-01, -4.68199163e-01, -1.22982775e+00,\n",
       "        -7.44660688e-01, -1.78589499e-01, -4.70590933e-01,\n",
       "        -7.66550394e-02, -7.66550394e-02, -7.33857711e-01,\n",
       "        -3.63704504e-01, -3.09572043e-01,  1.35394904e+00,\n",
       "         1.40335902e-01,  1.40335902e-01, -4.10444970e-01,\n",
       "        -2.00908685e+00, -8.48748316e-01, -4.40414599e-01,\n",
       "        -9.77127666e-01, -1.76750765e+00, -8.99073865e-01,\n",
       "        -1.16340887e+00, -7.74143398e-01, -7.28809170e-01,\n",
       "        -8.47007401e-03, -3.66535363e-03, -1.16422092e+00,\n",
       "        -1.16578838e+00, -5.25177175e-01, -8.96407447e-01,\n",
       "        -9.27261555e-01, -7.51627824e-01, -1.27679969e+00,\n",
       "         3.01087137e+00,  6.81892877e-02,  9.58945010e-01,\n",
       "        -9.22405488e-01, -1.31569801e+00, -1.12907483e+00,\n",
       "        -1.19419301e-01, -4.89225796e-01, -8.62811529e-01,\n",
       "        -5.72958659e-01, -1.77067444e-01,  1.07673809e+00,\n",
       "        -1.46055755e+00, -9.00579278e-01, -5.50557607e-01,\n",
       "         2.14747352e+00, -5.76425459e-01, -2.56765934e-01,\n",
       "        -2.56765934e-01, -2.56765934e-01, -3.07950612e-01,\n",
       "        -4.66401616e-01,  6.96896841e-01, -6.77685753e-01,\n",
       "        -1.55656104e+00,  5.65637931e-01, -8.05526781e-01,\n",
       "        -1.50311707e-02, -1.50311707e-02, -6.26182624e-01,\n",
       "         1.25190810e-01, -3.82736611e-01, -6.56423159e-01,\n",
       "        -1.05628112e-01, -4.07886581e-01,  6.92050014e-01,\n",
       "        -6.80774733e-01, -1.05628112e-01, -7.86693969e-01,\n",
       "        -8.08435335e-01, -5.74049902e-01, -1.64171291e-01,\n",
       "        -1.64171291e-01,  3.97024625e-01, -8.97417164e-01,\n",
       "         1.29742326e-01, -1.08600746e+00, -4.64934437e-01,\n",
       "        -6.83477884e-01, -3.00623415e-02, -1.50311707e-02,\n",
       "        -1.50311707e-02, -1.50311707e-02, -1.50311707e-02,\n",
       "        -1.33201983e+00, -1.13516925e-01, -6.75079863e-01,\n",
       "        -3.73959966e-02, -9.65341440e-01, -2.96197225e-01,\n",
       "         2.33764586e-01, -3.08273924e-01, -2.54264926e+00,\n",
       "        -3.42417737e-01, -3.28342581e-01, -1.64171291e-01,\n",
       "        -1.14907199e+00,  7.99999083e-01,  1.49488404e+00,\n",
       "        -4.63719021e-01, -3.28342581e-01, -1.64171291e-01,\n",
       "        -1.64171291e-01,  3.49106614e-01, -9.54010892e-01,\n",
       "        -5.25178858e-01, -8.31174950e-02, -9.50691890e-01,\n",
       "         1.14326487e+00, -2.90757508e-01, -2.90757508e-01,\n",
       "        -2.90757508e-01, -2.90757508e-01, -1.10860470e+00,\n",
       "        -6.45131536e-02, -6.45131536e-02, -1.05628112e-01,\n",
       "        -1.05628112e-01, -1.48113201e-01, -1.48113201e-01,\n",
       "        -6.45131536e-02, -6.45131536e-02,  9.07623426e-01,\n",
       "         6.30689204e-02,  1.55392984e+00,  5.72591172e-01,\n",
       "        -9.66423897e-03, -2.45922958e-01, -6.64320468e-02,\n",
       "        -7.75714103e-01, -5.39492266e-01, -2.57698548e-01,\n",
       "        -5.32360744e-01, -5.68985941e-01, -7.50362362e-01,\n",
       "        -8.01939905e-02, -7.29181344e-01,  3.95786420e-01,\n",
       "         1.82347881e-03, -4.79582498e-01,  1.02110932e-01,\n",
       "        -5.90261870e-01, -1.50311707e-02, -1.50311707e-02,\n",
       "        -1.50311707e-02, -1.50311707e-02, -1.48113201e-01,\n",
       "        -1.48113201e-01, -1.48113201e-01,  3.54600391e-01,\n",
       "        -4.92108699e-01, -1.33865250e-02, -3.82192739e-01,\n",
       "        -9.36881747e-02, -7.37012123e-01, -2.31014545e-01,\n",
       "        -1.48113201e-01, -1.48113201e-01, -1.47665240e-01,\n",
       "        -6.46146609e-01, -5.56381936e-01,  4.90190352e-01,\n",
       "        -4.55679694e-01,  1.25189321e-01, -1.21710534e-01,\n",
       "        -1.21710534e-01, -1.21710534e-01, -1.20138399e+00,\n",
       "        -2.95603224e-01, -6.09642688e-01,  1.89435245e-01,\n",
       "        -4.11125517e-01, -9.60422940e-01, -1.97038324e+00,\n",
       "        -1.19033694e+00, -1.22075214e+00, -1.89816587e+00,\n",
       "        -5.00195420e-01,  6.61177097e-01,  2.93348100e-01,\n",
       "         1.28318993e+00, -1.06914916e-01, -1.06914916e-01,\n",
       "         3.10080387e-01, -3.15278278e-01, -6.45131536e-02,\n",
       "        -6.45131536e-02, -7.98291484e-01, -1.14209037e+00,\n",
       "        -6.45131536e-02, -6.45131536e-02, -6.45131536e-02,\n",
       "        -2.60327469e-02, -2.45891288e-01, -9.18050692e-01,\n",
       "        -1.98667051e-02, -1.13438467e+00, -1.03370651e+00,\n",
       "        -8.41044760e-01, -1.05628112e-01, -1.05628112e-01,\n",
       "         5.55274185e-01, -9.23935632e-01, -1.07950285e+00,\n",
       "         1.06031561e+00, -3.78286325e-01, -2.56765934e-01,\n",
       "        -2.56765934e-01, -3.78111782e-01, -2.66395204e-01,\n",
       "         3.80414995e-01,  2.06642295e-02, -5.54407119e-02,\n",
       "        -1.31516051e-02, -1.86250443e+00,  5.58977722e-01,\n",
       "        -3.16141620e-01, -6.30890527e-01,  6.58451201e-03,\n",
       "         1.38274475e-01, -2.94675092e-01, -1.40598691e+00,\n",
       "        -3.26441079e-01, -5.89017388e-01, -3.36613381e-01,\n",
       "        -5.09458614e-01, -8.14095650e-01, -5.28256886e-01,\n",
       "         4.28314980e-01, -1.41096142e+00, -9.49462425e-01,\n",
       "        -1.32950861e+00, -1.07377219e-01, -1.06914916e-01,\n",
       "        -1.22632662e-01, -1.06914916e-01, -1.06914916e-01,\n",
       "        -8.76768536e-01, -1.05624738e+00, -6.83148608e-01,\n",
       "        -7.36639053e-01, -1.04615100e+00,  3.57125346e-01,\n",
       "        -8.32065191e-01, -5.33309564e-01, -1.06914916e-01,\n",
       "        -1.06914916e-01, -1.66904735e-01, -1.60967665e+00,\n",
       "        -1.01466668e+00, -4.82411373e-01, -7.38370665e-01,\n",
       "         1.29029489e+00,  4.33812729e-01, -7.12023418e-01,\n",
       "        -3.76378479e-01, -1.71204400e-01,  5.43518299e-02,\n",
       "        -1.05628112e-01, -1.05628112e-01, -1.26663496e-01,\n",
       "        -7.66550394e-02, -5.30767471e-01, -1.08573958e-01,\n",
       "        -7.66550394e-02,  1.18077220e+00, -1.54792323e+00,\n",
       "        -6.79184942e-01,  3.58703378e-01,  6.57287066e-01,\n",
       "         3.63140380e-01, -1.69710018e-01, -6.50697021e-01,\n",
       "        -1.80745757e-01, -5.33154095e-01, -2.93299267e-01,\n",
       "        -5.78434731e-01,  7.00320595e-02, -1.64171291e-01,\n",
       "        -1.64171291e-01, -4.26621732e-01,  1.98249688e-01,\n",
       "        -2.56765934e-01, -2.56765934e-01, -5.24233968e-01,\n",
       "        -5.45590017e-01,  7.45169673e-02, -3.66371440e-01,\n",
       "        -1.66157731e+00,  6.95499211e-01, -6.22357248e-01,\n",
       "         7.20479242e-02,  7.86798539e-02, -2.35348662e-01,\n",
       "        -1.21574237e+00, -1.53265289e+00, -7.29636331e-02,\n",
       "        -4.39647369e-02, -1.10553548e-02, -8.11614167e-01,\n",
       "        -2.80488051e-01, -2.03399998e+00,  4.34616133e-01,\n",
       "         2.23444005e-01, -1.36578623e+00, -2.45952398e-01,\n",
       "        -1.05628112e-01, -1.05628112e-01, -3.74550309e-01,\n",
       "        -1.07459477e-01, -1.53580322e-01,  8.90808887e-02,\n",
       "         2.12621432e-01, -7.66550394e-02, -7.66550394e-02,\n",
       "        -2.91835115e-02, -1.28673686e+00, -4.98123377e-01,\n",
       "        -1.48113201e-01, -1.48113201e-01, -6.67403905e-01,\n",
       "         3.35850955e-01, -1.04161734e+00, -2.52486646e-01,\n",
       "        -2.90757508e-01, -2.45863540e-02, -1.15700865e+00,\n",
       "        -5.00366097e-01, -1.23541870e+00,  8.07683173e-01,\n",
       "         4.24749674e-01, -8.75017268e-01, -3.81717104e-01,\n",
       "        -3.15927418e-01, -3.15927418e-01,  3.92052216e-03,\n",
       "         1.40335902e-01,  1.40335902e-01,  1.40335902e-01,\n",
       "        -2.34485631e-01,  5.02977604e-01, -3.18300431e-01,\n",
       "        -3.26382997e-02,  6.50922000e-01, -4.48032801e-01,\n",
       "        -1.28454188e+00,  4.72825697e-01, -1.49794986e-01,\n",
       "        -1.00856728e-01, -1.51807886e+00,  4.41097557e-01,\n",
       "        -7.09578836e-01, -9.65850081e-01, -7.73601881e-01,\n",
       "         2.19170121e+00,  4.95541774e-01, -1.21710534e-01,\n",
       "        -1.21710534e-01, -1.03618903e+00, -2.96790512e-01,\n",
       "         2.63018446e-01, -3.43636563e-01,  3.51346460e-01,\n",
       "         5.38223138e-01, -3.33994790e-01,  3.62844168e-02,\n",
       "         1.40335902e-01,  1.40335902e-01, -1.47763154e+00,\n",
       "        -1.08067407e+00,  1.55818662e-01,  4.60510747e-01,\n",
       "         2.17938341e+00, -9.62947553e-01, -1.15171063e-01,\n",
       "         3.93298740e-01, -4.03508793e-01, -1.50311707e-02,\n",
       "        -1.33865250e-02, -6.28413191e-01, -5.33167580e-01,\n",
       "         2.87710273e-01, -8.97917880e-01, -6.43819650e-01,\n",
       "        -5.69552246e-01,  5.17257828e-01, -1.44478917e-01,\n",
       "        -3.65178428e-01, -1.22248612e+00, -2.97863879e-01,\n",
       "        -2.97863879e-01, -1.17086953e+00, -4.34695360e-01,\n",
       "        -5.14349662e-02, -1.25656345e-01, -4.80314991e-01,\n",
       "        -5.37798680e-01, -7.86958549e-01,  3.24979432e-01,\n",
       "        -1.87844123e-02,  9.71870218e-01, -2.54089674e-01,\n",
       "         3.85649513e-01, -3.62645335e-01,  7.04272814e-01,\n",
       "         8.25374474e-02, -4.37347725e-01, -9.44972743e-01,\n",
       "         1.45660254e+00,  8.85851031e-02, -1.06914916e-01,\n",
       "        -1.06914916e-01,  1.40335902e-01,  1.40335902e-01,\n",
       "        -6.55267022e-01, -4.30810209e-01, -1.07558638e-01,\n",
       "        -1.07558638e-01, -5.80836253e-01, -1.72964157e-01,\n",
       "        -1.98676725e+00, -1.33943914e+00, -1.17498731e+00,\n",
       "        -6.99778444e-01, -1.31447985e+00, -5.66102401e-01,\n",
       "        -1.87770023e+00, -3.67007376e-01, -8.81654168e-01,\n",
       "        -1.91122609e-01, -4.43442785e-01,  1.84747569e-01,\n",
       "        -1.86015546e-01, -9.23454306e-01,  2.11439918e-01,\n",
       "        -2.56765934e-01, -2.56765934e-01, -2.56765934e-01,\n",
       "        -2.39227247e-01,  1.94400942e-01,  4.68581266e-02,\n",
       "         5.48117370e-02,  3.43419194e-02, -3.69831876e-01,\n",
       "         4.02032249e-01, -8.16336089e-01, -1.57636970e+00,\n",
       "         2.57723062e-01, -5.28511612e-01,  1.80560014e+00,\n",
       "        -3.12729431e-01, -3.59852086e-01, -8.26615552e-01,\n",
       "        -1.06914916e-01, -1.06914916e-01, -7.10724744e-01,\n",
       "        -9.90806767e-02, -2.91429618e-01, -8.36286705e-01,\n",
       "        -2.73105957e-01, -1.21710534e-01, -1.19419301e-01,\n",
       "        -1.40676666e+00, -1.96623616e-01,  5.18110745e-01,\n",
       "        -1.07045799e+00,  4.67281646e-01, -6.33904704e-01,\n",
       "        -6.59675055e-02, -4.35966887e-01,  3.77147552e-01,\n",
       "        -3.27697945e-01, -1.03611602e+00,  1.29368953e-02,\n",
       "        -8.74361989e-02, -1.15101542e+00,  3.18443681e-01,\n",
       "        -1.35503929e-01, -1.66510600e-01, -9.82715611e-02,\n",
       "        -3.00623415e-02, -1.50311707e-02,  1.06715105e+00,\n",
       "         6.88498689e-02,  4.07169905e-01, -3.23284500e-02,\n",
       "        -9.08725776e-01, -1.79402941e-01,  2.12425453e-01,\n",
       "        -3.25798093e-01,  1.06096773e-01,  2.20440203e+00,\n",
       "        -1.29224143e-01, -1.50311707e-02, -1.50311707e-02,\n",
       "        -1.50311707e-02, -1.50311707e-02, -1.50311707e-02,\n",
       "         3.40439324e+00,  2.37867621e+00, -4.31694303e-01,\n",
       "        -1.48113201e-01, -1.48113201e-01, -9.02206823e-01,\n",
       "         3.66872794e-01,  4.50011641e-01, -1.84929430e+00,\n",
       "         2.68593211e-01, -4.11373935e-01,  8.99898378e-01,\n",
       "        -1.05628112e-01,  5.62501265e-02, -1.54053611e-01,\n",
       "        -6.21606271e-03, -2.82253992e-01, -9.24551497e-01,\n",
       "         2.27366684e-01,  3.75580195e-01, -1.27817112e+00,\n",
       "         3.83722471e-01, -7.65597391e-01,  3.24731218e-01,\n",
       "         1.05386031e+00,  1.07547657e+00,  3.70965247e-01,\n",
       "        -1.42007641e+00, -5.06659869e-01, -9.42600961e-01,\n",
       "         4.74571953e-01, -4.20181274e-01,  2.19059050e-01,\n",
       "        -1.01923628e+00,  4.60185415e-02,  8.67344502e-02,\n",
       "        -1.79555914e-01, -8.28484915e-01,  4.02269650e-01,\n",
       "        -1.15543417e+00, -6.55876763e-01, -2.90757508e-01,\n",
       "        -2.90757508e-01, -2.56765934e-01, -2.56765934e-01,\n",
       "        -2.56765934e-01, -6.85364000e-01,  6.51998628e-02,\n",
       "        -7.95491845e-01, -1.44661665e+00, -1.23863067e-01,\n",
       "        -8.99645974e-01, -1.14878444e+00, -7.37537187e-01,\n",
       "        -8.83371393e-01, -3.28836922e-01,  1.24004150e-01,\n",
       "        -9.18628032e-01, -7.15757311e-01, -8.75215653e-01,\n",
       "        -2.55879554e-01, -3.71711853e-01, -2.07582601e-01,\n",
       "         7.99421517e-01, -4.81855820e-01, -8.02070940e-01,\n",
       "        -1.16450635e+00, -9.17573235e-01, -1.14349044e+00,\n",
       "        -4.14693163e-01, -1.07468736e-01, -5.48566015e-01,\n",
       "        -1.48113201e-01,  4.14378750e-02, -4.04473283e-01,\n",
       "        -2.97863879e-01, -2.90757508e-01, -2.90757508e-01,\n",
       "         2.90871530e-02, -1.06388059e+00, -2.44032481e-01,\n",
       "         2.35100922e-01,  1.48302183e+00, -1.48113201e-01,\n",
       "        -1.48113201e-01, -1.61772009e-01, -1.48113201e-01,\n",
       "         3.76596615e-01, -5.25760092e-01, -2.39227247e-01,\n",
       "         1.57607889e-01, -4.98400198e-01, -9.35475252e-01,\n",
       "         1.44340996e-02,  1.01896696e-01, -1.57809743e-01,\n",
       "         7.21814648e-02,  2.54391439e-01, -1.30823005e+00,\n",
       "         1.59521944e-01, -1.05628112e-01, -1.05628112e-01,\n",
       "         8.25602054e-01, -5.04720440e-01, -3.34868988e-01,\n",
       "        -1.22741966e+00, -3.16840357e-01, -6.94992540e-01,\n",
       "        -2.97863879e-01, -8.34666760e-02,  1.42662858e-01,\n",
       "        -1.43050057e+00, -2.02256412e+00, -7.64403975e-01,\n",
       "        -1.29796218e+00,  5.12288983e-01, -1.81983767e+00,\n",
       "        -8.96706435e-01, -1.28847495e+00, -2.10902467e-01,\n",
       "        -3.28424709e-03, -2.99193770e-03, -1.02669302e+00,\n",
       "         1.32670650e-01,  2.69251738e-01,  9.34431060e-01,\n",
       "        -4.62802824e-01,  1.39708190e-01, -7.86229043e-01,\n",
       "         3.73865686e-01, -1.18678158e-01, -1.06914916e-01,\n",
       "        -1.06914916e-01, -1.52413705e-01, -9.36813936e-01,\n",
       "        -4.95684861e-01, -6.45131536e-02, -6.45131536e-02,\n",
       "        -6.45131536e-02, -1.14234249e+00, -4.03655723e-01,\n",
       "        -2.97863879e-01,  3.14416800e-01,  5.60629924e-01,\n",
       "        -2.80967981e-01, -2.48313922e-01, -1.06914916e-01,\n",
       "        -1.05186254e-01, -2.33446876e-01,  8.70924647e-01,\n",
       "        -2.90757508e-01, -2.90757508e-01, -2.90757508e-01,\n",
       "        -3.55497642e-01,  8.26425459e-01, -1.02537299e+00,\n",
       "         2.22026835e-01,  1.61288783e-01, -4.16962569e-01,\n",
       "         9.24447203e-02, -1.40212295e+00, -3.18468254e-01,\n",
       "        -4.48738056e-01, -1.38995381e-02, -3.01838368e-01,\n",
       "        -8.28749956e-02, -1.29821073e-01,  2.75542998e-01,\n",
       "        -6.97418313e-01, -1.44625573e+00, -5.26938643e-01,\n",
       "        -1.06914916e-01, -1.06914916e-01,  6.63119257e-01,\n",
       "        -8.61422474e-01, -9.86486721e-01, -1.22342293e+00,\n",
       "        -1.63752875e+00, -7.57151191e-01, -5.37673176e-02,\n",
       "        -3.94084616e-01, -1.06914916e-01, -1.05186254e-01,\n",
       "        -5.91323835e-01, -5.07283858e-01, -1.11107505e+00,\n",
       "        -6.45131536e-02, -6.45131536e-02,  2.70157799e+00,\n",
       "        -2.00024227e-01,  3.88532869e-01,  9.77178404e-02,\n",
       "        -7.35922513e-01,  9.16784636e-02,  1.67676319e+00,\n",
       "         1.79283732e+00, -3.19338692e-01,  1.26481944e+00,\n",
       "         1.36951899e-01, -4.22833986e-01, -3.12579672e-01,\n",
       "        -6.40162334e-01,  5.47453677e-01, -2.98832969e-01,\n",
       "         1.98415142e-02, -9.31504652e-01, -4.85190552e-02,\n",
       "        -1.64171291e-01, -1.64171291e-01,  3.76373026e-01,\n",
       "         1.60870923e-01, -4.59115971e-01, -2.80246330e-01,\n",
       "        -2.68729770e-01, -1.98780678e-01, -1.03278350e+00,\n",
       "        -7.51114888e-01,  2.28173147e-01, -6.59043539e-01]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "LogisticRegr.fit(x_train, y_train)\n",
    "LogisticRegr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the train data set\n",
    "prediction_reg=LogisticRegr.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9469369876728615\n"
     ]
    }
   ],
   "source": [
    "# Lets measure the score\n",
    "score = LogisticRegr.score(x_train, y_train)\n",
    "print(score)\n",
    "\n",
    "# score is nothing but the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[29570   150]\n",
      " [ 1546   696]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "\n",
    "y_train.shape\n",
    "prediction_reg.shape\n",
    "\n",
    "cm = metrics.confusion_matrix(y_train, prediction_reg)\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9469369876728615"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy\n",
    "acc=(cm[0][0] + cm[1][1])/(cm[0][0]+cm[0][1]+cm[1][0]+cm[1][1])\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.31043710972346117"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Senstivity\n",
    "sens=cm[1][1]/(cm[1][1]+cm[1][0])\n",
    "sens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9949528936742934"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specifisity\n",
    "spec=cm[0][0]/(cm[0][0]+cm[0][1])\n",
    "spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8226950354609929"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Precision\n",
    "prec=cm[1][1]/(cm[1][1]+cm[0][1])\n",
    "prec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9949528936742934"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recall: Same as Specifisity\n",
    "rec=spec\n",
    "rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9006615560944164"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# F1 Score\n",
    "(2*prec*rec)/(prec+rec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The value of F1 Score on Train data is around 0.90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Doc_ID</th>\n",
       "      <th>#2016</th>\n",
       "      <th>#affirmation</th>\n",
       "      <th>#affirmations</th>\n",
       "      <th>#allahsoil</th>\n",
       "      <th>#altwaystoheal</th>\n",
       "      <th>#altwaystoheal  #healthy</th>\n",
       "      <th>#amazing</th>\n",
       "      <th>#anxiety</th>\n",
       "      <th>...</th>\n",
       "      <th>yes</th>\n",
       "      <th>yet</th>\n",
       "      <th>yo</th>\n",
       "      <th>you</th>\n",
       "      <th>you!</th>\n",
       "      <th>you.</th>\n",
       "      <th>you?</th>\n",
       "      <th>young</th>\n",
       "      <th>id</th>\n",
       "      <th>tweet_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 875 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Doc_ID  #2016  #affirmation  #affirmations  #allahsoil  \\\n",
       "0  0           1       0.0    0.0           0.0            0.0          \n",
       "1  1           2       0.0    0.0           0.0            0.0          \n",
       "2  2           3       0.0    0.0           0.0            0.0          \n",
       "3  3           4       0.0    0.0           0.0            0.0          \n",
       "4  4           5       0.0    0.0           0.0            0.0          \n",
       "\n",
       "   #altwaystoheal  #altwaystoheal  #healthy  #amazing  #anxiety   ...     yes  \\\n",
       "0  0.0             0.0                       0.0       0.0        ...     0.0   \n",
       "1  0.0             0.0                       0.0       0.0        ...     0.0   \n",
       "2  1.0             1.0                       0.0       0.0        ...     0.0   \n",
       "3  0.0             0.0                       0.0       0.0        ...     1.0   \n",
       "4  0.0             0.0                       0.0       0.0        ...     0.0   \n",
       "\n",
       "   yet   yo  you  you!  you.  you?  young  id  tweet_y  \n",
       "0  0.0  0.0  0.0  0.0   0.0   0.0   0.0   NaN NaN       \n",
       "1  0.0  0.0  0.0  0.0   0.0   0.0   0.0   NaN NaN       \n",
       "2  0.0  0.0  0.0  0.0   0.0   0.0   0.0   NaN NaN       \n",
       "3  0.0  0.0  0.0  0.0   0.0   0.0   0.0   NaN NaN       \n",
       "4  0.0  0.0  0.0  0.0   0.0   0.0   0.0   NaN NaN       \n",
       "\n",
       "[5 rows x 875 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets try and calculate the value on test data\n",
    "# importing test_DTM.csv file\n",
    "test_df=pd.read_csv(dr + \"\\\\test_DTM.csv\")\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Doc_ID', '#2016', '#affirmation', '#affirmations',\n",
       "       '#allahsoil', '#altwaystoheal', '#altwaystoheal  #healthy', '#amazing',\n",
       "       '#anxiety',\n",
       "       ...\n",
       "       'yes', 'yet', 'yo', 'you', 'you!', 'you.', 'you?', 'young', 'id',\n",
       "       'tweet_y'],\n",
       "      dtype='object', length=875)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the x_test\n",
    "test_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17197, 870)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing 'Unnamed: 0' and 'Doc_ID' column\n",
    "pos=[i not in ['Unnamed: 0','Doc_ID','dummy','id','label','tweet_y'] for i in test_df.columns ]\n",
    "x_test=test_df[test_df.columns[pos]]\n",
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Running them Model on x_test\n",
    "# Make predictions on the train data set\n",
    "prediction_reg=LogisticRegr.predict(x_test)\n",
    "prediction_reg[0:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "466"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos=[i == 1 for i in prediction_reg]\n",
    "sum(pos) # Total tweets labelled as 1 are 466"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Doc_ID</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Doc_ID  0\n",
       "0  1       0\n",
       "1  2       0\n",
       "2  3       0\n",
       "3  4       0\n",
       "4  5       0"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test_complete=pd.concat([test_df['Doc_ID'],pd.DataFrame(list(prediction_reg))],axis=1)\n",
    "Test_complete.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17197, 2)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Doc_ID</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Doc_ID  label\n",
       "0  1       0    \n",
       "1  2       0    \n",
       "2  3       0    \n",
       "3  4       0    \n",
       "4  5       0    "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test_complete.columns=['Doc_ID','label']\n",
    "Test_complete.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label\n",
       "0  0    \n",
       "1  0    \n",
       "2  0    \n",
       "3  0    \n",
       "4  0    "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing the Doc_ID as this is not required for submission\n",
    "Test_complete2=Test_complete.drop(['Doc_ID'],axis=1)\n",
    "Test_complete2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing it back to the folder \n",
    "Test_complete2.to_csv(dr + \"\\\\test_predictions.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
